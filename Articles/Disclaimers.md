
## Housekeeping Details

Throughout these articles, we will be using scala-spark for all of the code examples, using the following specs:

- Spark version 3.0.1
- Scala 2.12.11
- Java 11
- Apache Maven 3.6.3 for jar building

### Additional Notes
- These articles are NOT meant to be a Spark programming tutorial. Though we will use/explain various code examples throughout, there are plenty of sources that cover the "how-tos" of Spark programming. These articles assume that you have a basic knowledge of Spark programming, or at least know how to look up basic code documentation
- I am NOT claiming that Apache Spark is better than Pandas or any of the common DS tools. I firmly believe that each toolkit is optimal for different use cases, data sizes, and team sizes. No one tool is comprehensively better than the others.
- *Earlier I mentioned that a lot of DS post-grad programs (General Assembly, Metis, Udacity, etc.) don't cover these topics extensively. That's not to say that these aren't fantastic programs. I personally graduated from the General Assembly Immersive Data Science program in 2017 and Udacity Data Engineering Nanodegree Program in 2020, and can vouch for the quality of their curriculums and material. There just simply aren't enough hours to cover everything